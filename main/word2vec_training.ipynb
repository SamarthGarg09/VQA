{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "from time import time\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['ner', 'parser'])\n",
    "\n",
    "def clean(texts):\n",
    "    text = [token.lemma_ for token in texts]\n",
    "    if len(text)>2:\n",
    "        return \" \".join(text)\n",
    "\n",
    "remove_symbols = (re.sub(r\"[^a-zA-Z]+\", \" \", str(row)).lower() for row in df.question)\n",
    "\n",
    "t = time()\n",
    "clean_txt = [clean(text) for text in nlp.pipe(remove_symbols, batch_size=5000, n_process=-1)]\n",
    "print(f\"Time to preprocess the text : {round((time()-t)/60, 2)}\")\n",
    "\n",
    "df_clean = pd.DataFrame({\"preprocessed_text\": clean_txt})\n",
    "df_clean = df_clean.dropna().drop_duplicates()\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "from collections import defaultdict\n",
    "import multiprocessing\n",
    "\n",
    "sents = [sent.split() for sent in df_clean.preprocessed_text]\n",
    "phrases = Phrases(sents, min_count=30, progress_per=10000)\n",
    "phrasegrams = Phraser(phrases)\n",
    "sentences = phrasegrams[sents]\n",
    "\n",
    "word_freq = defaultdict(int)\n",
    "for sent in sents:\n",
    "    for token in sent:\n",
    "        word_freq[token] += 1\n",
    "print(f\"Total words :\", len(word_freq))\n",
    "\n",
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "word2vec = Word2Vec(\n",
    "    min_count=20,\n",
    "    window=10, \n",
    "    vector_size=300,\n",
    "    alpha=0.03,\n",
    "    min_alpha=0.0007,\n",
    "    negative=20,\n",
    "    workers=cores-1\n",
    ")\n",
    "\n",
    "t = time()\n",
    "word2vec.build_vocab(sentences, progress_per=10000)\n",
    "print(f\"Time to built vocabulary : {round((time()-t)/60, 2)} min\")\n",
    "\n",
    "t = time()\n",
    "word2vec.train(sentences, total_examples=word2vec.corpus_count, epochs=30, report_delay=1)\n",
    "print(f\"Time to train the model : {round((time()-t)/60, 2)} min.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76fc3e2f6304e93683fc74be6b0d3417f407df6ca178970a4007109313a40cfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
